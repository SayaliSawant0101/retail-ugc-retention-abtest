**ğŸ§ª Improving Repeat Purchase for Paid-Acquisition Users using Post-Purchase UGC**

A Retail A/B Testing Case Study

**ğŸ“Œ Overview**

Paid-acquisition users in retail apps often convert on their first purchase but fail to return, leading to low retention and heavy reliance on discounts. This project investigates whether post-purchase confidence reinforcement using authentic user-generated content (UGC) can improve repeat purchase behavior without increasing promotions or harming customer experience.

Using a controlled A/B experiment, we test a non-monetary retention lever targeted specifically at paid-acquisition users and evaluate its impact across retention, margin proxies, and customer quality metrics.

**â“ Problem Statement**

Retail teams observed a persistent gap in D30 repeat purchase between:

Paid-acquisition users (lower retention, higher discount dependency)

Organic users (higher trust, stronger repeat behavior)

Key question:

Is paid user churn driven by poor acquisition quality â€” or by lack of post-purchase confidence and trust?

**ğŸ’¡ Hypothesis**

Providing authentic social proof after delivery (via UGC) will reduce buyerâ€™s remorse and increase repeat purchase among paid-acquisition users, without increasing returns or discount dependency.

**ğŸ§ª Experiment Design**
Population

First-time purchasers acquired via paid channels

Organic users used only as a benchmark (not randomized)

Variants

Control:
Order confirmation + shipping emails only

Treatment:
Control emails plus a UGC confidence email sent 5â€“7 days after delivery, showing how real customers use or style the product

Why post-delivery?

This timing aligns with:

Initial product usage

Peak buyerâ€™s remorse window

Return decision period

**ğŸ“ Metrics & Measurement Strategy**
Primary Metric

D30 Repeat Purchase Rate
Measures relationship formation beyond the first transaction

Secondary Metrics

Time to next purchase (natural vs forced repeats)

Repeat order value (quality of repeat behavior)

Discount usage on repeat (margin dependency proxy)

Guardrails

Return rate (expectation mismatch)

Email engagement (diagnostic only)

**ğŸ“ˆ Outcome Snapshot**
Primary Impact (Paid Users)

Repeat Purchase (D30)

Control: 8.9%

Treatment: 14.8%

+5.9 pp lift (+66%)

p < 0.001, 95% CI: [+4.8 pp, +7.1 pp]

Quality & Risk Checks

Return rate: No significant increase

Repeat order value: Stable

Time to next purchase: No forced urgency

Margin Signal

Discount usage on repeat

Control: 49.8%

Treatment: 39.1%

â€“10.7 pp reduction (p < 0.001)

## ğŸ“Š Key Visuals

### Repeat Purchase Lift (Paid Users)
![Repeat Rate](reports/figures/repeat_rate.png)

### Discount Dependency on Repeat Orders
![Discount Dependency](reports/figures/discount_dependency.png)

### Lift by Category
![Category Lift](reports/figures/category_lift.png)

### Lift by Region
![Region Lift](reports/figures/region_lift.png)



**ğŸ” Before vs After Funnel (Paid Users)**
Before

First purchase â†’ âœ…

Post-purchase confidence â†’ âŒ

Repeat purchase (D30): 8.9%

High discount reliance

After

First purchase â†’ âœ…

Confidence reinforcement via UGC â†’ âœ…

Repeat purchase (D30): 14.8%

Lower discount dependency

No increase in returns

Interpretation:
The experiment reduced post-purchase uncertainty and converted one-time buyers into repeat customers without incentives.

**ğŸ” Diagnostic Insights**

Email openers: 18.1% repeat rate

Non-openers: 13.0% repeat rate

Highest category lift: Home, Apparel, Footwear

Geography: Positive lift across all regions (NE & West strongest)

This confirms the mechanism: confidence reinforcement works when users engage.

**ğŸ“ Experiment Decision Memo (Summary)**

Decision: âœ… Ship and scale
Why:

Strong, statistically significant retention lift

No guardrail violations

Reduced discount dependency

Next steps:

Roll out to all paid users with monitoring

Optimize subject lines to increase opens

Personalize UGC by category

**âš ï¸ Risks & Considerations**

UGC quality and freshness must be maintained

Over-messaging could cause fatigue if not capped

Some categories may require educational content instead of styling

Long-term LTV impact should be monitored beyond D30

**ğŸ› ï¸ Tech Stack & Methods**
Tools

Python (pandas, numpy, scipy, statsmodels)

Jupyter Notebook

GitHub for version control and documentation

Methods

User-level A/B testing

Two-proportion z-tests with confidence intervals

Non-parametric tests for skewed distributions

Cohort and segmentation analysis

Guardrail monitoring for unintended effects

ğŸ“‚ Repository Structure
â”œâ”€â”€ data/          # Synthetic experiment dataset
â”œâ”€â”€ notebooks/     # End-to-end analysis notebook
â”œâ”€â”€ src/           # Reusable metric utilities
â”œâ”€â”€ reports/       # Decision memo & figures
â””â”€â”€ README.md

**â­ Why This Project Matters**

This case study demonstrates:

End-to-end experimentation thinking

Business-driven metric selection

Causal reasoning and guardrail discipline

Product and growth decision-making at scale

**â–¶ï¸ How to Run**
pip install -r requirements.txt
jupyter notebook notebooks/01_ugc_email_abtest_case_study.ipynb

**ğŸš€ Next Steps**

Subject line A/B tests to increase open rates

Personalized UGC ranking

Long-term LTV and retention tracking

